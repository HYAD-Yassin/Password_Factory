{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNZFfV07ZfAMaBHEeGXNW68",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HYAD-Yassin/Password_Factory/blob/main/LTSM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EIy-gmtGnjnn",
        "outputId": "34481f17-8fd6-4583-c538-79fcac0456ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            " 100K_LSTM_passwords.txt\n",
            " 10K_LSTM_passwords.txt\n",
            " 1M_LSTM_passwords.txt\n",
            " acoustique_voy_orales_20loc_ESTER_NCCFr_contexte_freqLex_distCentroide.csv\n",
            " AllDataSet_Filtred.txt\n",
            " AllDataSet.txt\n",
            "'Alternance (1).gdoc'\n",
            " Alternance.gdoc\n",
            " archive.zip\n",
            " Ashley-Madison_Ini.txt\n",
            " Ashley-Madison.txt\n",
            "'Colab Notebooks'\n",
            " DATABASE_Password.zip\n",
            " data.zip\n",
            " Filtered-Ashley-Madison.txt\n",
            " Filtered_PWD.txt\n",
            " generated100k_GRU_passwords.txt\n",
            " generated100K_LSTM_passwords.txt\n",
            " generated10K_LSTM_passwords.txt\n",
            " generated1M_GRU_passwords.txt\n",
            " generated200K_LSTM_passwords.txt\n",
            " generated2_passwords.txt\n",
            " generated50K_LSTM_passwords.txt\n",
            " generated_GRU_passwords.txt\n",
            " generated_LSTM_passwords.txt\n",
            " generated_passwords.txt\n",
            " gru_model.pth\n",
            " histo2.png\n",
            " histogram1.png\n",
            " Letter.gdoc\n",
            " lstm_model2.pth\n",
            " lstm_model.pth\n",
            " my_model\n",
            " nameGeneration.py\n",
            " Passwords.txt\n",
            " pwd_2Rnn.pth\n",
            " pwd_Rnn.pth\n",
            " __pycache__\n",
            " reduced_Ashley-Madison.txt\n",
            " rnn.pt\n",
            "'Untitled document (1).gdoc'\n",
            "'Untitled document.gdoc'\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!ls drive/MyDrive/"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Dataset**"
      ],
      "metadata": {
        "id": "nTNoVdBGnwsm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import random\n",
        "from collections import Counter\n",
        "import os\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "# Check if CUDA is available, else use CPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "file_path = '/content/drive/My Drive/Ashley-Madison.txt'\n",
        "\n",
        "# Read the data\n",
        "with open(file_path, 'r', encoding='utf-8') as file:\n",
        "    passwords = file.read().splitlines()  # Each password is a line\n",
        "\n",
        "print(f\"The total passwords in The DataSet is: {len(passwords)}\")\n",
        "\n",
        "\n",
        "# Preprocessing: Create a dictionary to convert characters to integers and back\n",
        "all_chars = ''.join(set(''.join(passwords)))\n",
        "n_characters = len(all_chars)\n",
        "char_to_int = {char: i for i, char in enumerate(all_chars)}\n",
        "int_to_char = {i: char for i, char in enumerate(all_chars)}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d3K2fM3Inx01",
        "outputId": "98fd0d28-a65e-4a83-ff70-b7fae05933bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The total passwords in The DataSet is: 338333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**LSTM Model**"
      ],
      "metadata": {
        "id": "AzdduL6TpYpS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTM(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size, n_layers):\n",
        "        super(LSTM, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.n_layers = n_layers\n",
        "\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers=n_layers)\n",
        "        self.i2o = nn.Linear(hidden_size, output_size)\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        lstm_out, hidden = self.lstm(input.view(1, 1, -1), hidden)\n",
        "        output = self.i2o(lstm_out.view(1, -1))\n",
        "        output = self.dropout(output)\n",
        "        output = self.softmax(output)\n",
        "        return output, hidden\n",
        "\n",
        "    def init_hidden(self):\n",
        "        return (torch.zeros(self.n_layers, 1, self.hidden_size),\n",
        "                torch.zeros(self.n_layers, 1, self.hidden_size))"
      ],
      "metadata": {
        "id": "ZqVfqvPXpY3g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Training Loop:**"
      ],
      "metadata": {
        "id": "qlDiTB_Tpu5R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def char_tensor(string):\n",
        "    tensor = torch.zeros(len(string), n_characters)  # Create a 2D tensor\n",
        "    for c in range(len(string)):\n",
        "        char_idx = char_to_int[string[c]]\n",
        "        tensor[c][char_idx] = 1  # One-hot encoding\n",
        "    return tensor\n",
        "\n",
        "# Training function\n",
        "def train_on_full_dataset(passwords, lstm, criterion, optimizer):\n",
        "    total_loss = 0\n",
        "\n",
        "    for password in passwords:\n",
        "        input_line_tensor = char_tensor(password[:-1]).to(device)  # Move to device\n",
        "        target_line_tensor = char_tensor(password[1:]).to(device)  # Move to device\n",
        "\n",
        "        hidden, cell = lstm.init_hidden()\n",
        "        hidden = hidden.to(device)  # Move to device\n",
        "        cell = cell.to(device)  # Move to device\n",
        "\n",
        "        lstm.zero_grad()\n",
        "        loss = 0\n",
        "\n",
        "        for i in range(input_line_tensor.size(0)):\n",
        "            input_tensor = input_line_tensor[i].unsqueeze(0)  # already one-hot encoded\n",
        "            target_char = target_line_tensor[i].argmax().unsqueeze(0)  # Get the index of the target character\n",
        "\n",
        "            output, (hidden, cell) = lstm(input_tensor, (hidden, cell))\n",
        "            l = criterion(output, target_char)\n",
        "            loss += l\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item() / input_line_tensor.size(0)\n",
        "\n",
        "    return total_loss / len(passwords)\n",
        "\n",
        "# Initialize network, optimizer, and loss function\n",
        "n_characters = len(char_to_int)  # Number of unique characters\n",
        "hidden_size = 128\n",
        "output_size = n_characters\n",
        "n_layers = 2  # Number of LSTM layers\n",
        "lstm = LSTM(n_characters, hidden_size, output_size, n_layers).to(device)\n",
        "optimizer = optim.Adam(lstm.parameters(), lr=0.005)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Training loop\n",
        "n_epochs = 2\n",
        "for epoch in range(1, n_epochs + 1):\n",
        "    loss = train_on_full_dataset(passwords, lstm,  criterion, optimizer)\n",
        "    print(f'Epoch: {epoch} of {n_epochs}, Loss: {loss:.4f}')\n"
      ],
      "metadata": {
        "id": "HyCEIw-QpgWy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "outputId": "1c43e8a4-1e04-4f9c-c71c-c0d9d1ab6799"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-db0259b777f1>\u001b[0m in \u001b[0;36m<cell line: 49>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0mn_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_on_full_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpasswords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlstm\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Epoch: {epoch} of {n_epochs}, Loss: {loss:.4f}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-db0259b777f1>\u001b[0m in \u001b[0;36mtrain_on_full_dataset\u001b[0;34m(passwords, lstm, criterion, optimizer)\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0mtarget_char\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget_line_tensor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Get the index of the target character\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m             \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m             \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_char\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-0ced2736a790>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hidden)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mlstm_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mi2o\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlstm_out\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    877\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    878\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 879\u001b[0;31m             result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[0m\u001b[1;32m    880\u001b[0m                               self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[1;32m    881\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(lstm.state_dict(), '/content/drive/My Drive/lstm_model2.pth')\n",
        "\n",
        "lstm.load_state_dict(torch.load('/content/drive/My Drive/lstm_model2.pth'))\n",
        "lstm.eval()"
      ],
      "metadata": {
        "id": "vZxFuowKgZhV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f200ada-998f-4b06-9c56-5f8d286c911a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LSTM(\n",
              "  (lstm): LSTM(92, 128, num_layers=2)\n",
              "  (i2o): Linear(in_features=128, out_features=92, bias=True)\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (softmax): LogSoftmax(dim=1)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rnn = LSTM(n_characters, hidden_size, n_characters, n_layers).to(device)\n"
      ],
      "metadata": {
        "id": "k6a7k-TxUO3e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Passwords Generation**"
      ],
      "metadata": {
        "id": "9w5KdRkPVIU3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import torch\n",
        "\n",
        "def generate_password(model, temperature, all_chars, char_to_int, device, int_to_char):\n",
        "    model.eval()\n",
        "    hidden, cell = model.init_hidden()  # corrected method name\n",
        "    hidden = hidden.to(device)  # move to correct device\n",
        "    cell = cell.to(device)  # move to correct device\n",
        "\n",
        "    start_str = random.choice(all_chars)\n",
        "    predict_len = random.randint(6, 15)\n",
        "\n",
        "    input_tensor = char_tensor(start_str).to(device)\n",
        "    predicted_str = start_str\n",
        "    last_char = input_tensor[-1]\n",
        "\n",
        "    for p in range(predict_len):\n",
        "        output, (hidden, cell) = model(last_char.unsqueeze(0), (hidden, cell))\n",
        "        output_dist = output.data.view(-1).div(temperature).exp()\n",
        "        output_dist = torch.clamp(output_dist, min=0.0001, max=1.0)\n",
        "        output_dist = output_dist / torch.sum(output_dist)\n",
        "        top_char = torch.multinomial(output_dist, 1)[0]\n",
        "\n",
        "        predicted_char = int_to_char[top_char.item()]\n",
        "        predicted_str += predicted_char\n",
        "        last_char = char_tensor(predicted_char).to(device)\n",
        "\n",
        "    return predicted_str\n",
        "\n",
        "def generate_passwords_to_file(model, num_pwd, file_path, temperature, all_chars, char_to_int, device, int_to_char):\n",
        "    model.to(device)\n",
        "    with open(file_path, 'w') as file:\n",
        "        for _ in range(num_pwd):\n",
        "            password = generate_password(model, temperature, all_chars, char_to_int, device, int_to_char)  # corrected argument list\n",
        "            file.write(password + '\\n')\n",
        "\n",
        "# Example usage:\n",
        "num_pwd = 1000000\n",
        "output_file_path = '/content/drive/My Drive/generated1M_LSTM_passwords.txt'\n",
        "generate_passwords_to_file(lstm, num_pwd, output_file_path, 0.85, all_chars, char_to_int, device, int_to_char)\n"
      ],
      "metadata": {
        "id": "SyUX2VduTn4B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Calculate Accuracy**"
      ],
      "metadata": {
        "id": "EZiZw-0QVK9q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_accuracy_and_matches(original_dataset_path, generated_file_path):\n",
        "    # Load the original dataset\n",
        "    with open(original_dataset_path, 'r') as file:\n",
        "        original_passwords = set(file.read().splitlines())\n",
        "\n",
        "    # Load generated passwords\n",
        "    with open(generated_file_path, 'r') as file:\n",
        "        generated_passwords = file.read().splitlines()\n",
        "\n",
        "    # Find matches\n",
        "    matches = [password for password in generated_passwords if password in original_passwords]\n",
        "    dub = set(matches)\n",
        "    # Calculate accuracy based on full line matches\n",
        "    accuracy = (len(dub) / len(generated_passwords)) * 100 if generated_passwords else 0\n",
        "    return accuracy, matches\n",
        "\n",
        "# Paths to the files\n",
        "original_dataset_path = '/content/drive/My Drive/Ashley-Madison_Ini.txt'  # Modify as needed\n",
        "generated_file_path = '/content/drive/My Drive/100K_RNN_Passwords.txt'  # Modify as needed\n",
        "\n",
        "# Calculate accuracy and get matches\n",
        "accuracy, matching_passwords = calculate_accuracy_and_matches(original_dataset_path, generated_file_path)\n",
        "print(f\"Accuracy: {accuracy:.2f}%\")\n",
        "print(\"Matching Passwords Number:\", len(matching_passwords))\n",
        "print(\"Matching Passwords:\", set(matching_passwords))"
      ],
      "metadata": {
        "id": "-7wK9eY3VOef",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "264943df-dabe-4fd5-fe22-1ec1f7c5f367"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 1.41%\n",
            "Matching Passwords Number: 9282\n",
            "Matching Passwords: {'one', '29', 'cola', 'sss3', 'conn', 'pareja', 'cum', 'swt', 'R2', '8757', '96581', 'cera', 's', 'res', 'aff', '1111', '1212', '5903', '110', 'wa', 'care', 'ramadi', '9000', '621', '813', 'tecone', 'ella', 'tire', 'mare', '9448', 'me420', '185', 'gf', 'bone', '3232', '139', 'hamada', '712', 'nani', 'Chen', '121', '469', 'romy', '90', '4570', 'go', 'mrtr', '8083', '74720', 'fang', '3204', '10', '111', '97', '727', 'donde', 'vase', 'chonch', 'jaci', 'miken', 'm', 'ssssss', 'ro', 'nerd', 'sones', '223', 'AS19', '125', 'have', '730', 'ndes', 'lll', '269', 'rocko', '2435', 'lonis', 'nebo', 'nole', 'hire', '3467', '96', '80505', '990', '8995', 'md', '7012', '1009', 'rolla', 'gene', 'febe', 'mack', '814', 'tona', 'sabi', 'adee', 'mally', '217', 'lena', '1220', '2002', 'monet', 'fliar', '2113', '2133', 'mandi', '803', '3007', 'roe', 'assss', '3442', 'wetone', '1245', 're1121', 'nay', '8812', 'cman', '324', 'sowa', 'mone', '5218', 'nett', 'romo', 'sa11', 'g1234', '6952', 'gre', '104', 'dana', 'beno', 'momona', '3424', '812', 'tass', '522', 'runn', '719', 'nico', 'nec', 'cala', 'ssun', '2234', 'cash', 'htrd', 'erda', '69058', 'gh', 'red1', 'cow100', 'pani', '321', '7002', 'jone', '2490', 'cam12', 'nandy', 'riker', '304', 'steele', 'des', '1115', '620', 'miner', '723', 'semo', 'mane', 'cd', 'pandi', '81281', '807', 'neg', 'pack', 'ber', 'band', '3425', '1920', 'swc', '2969', 'sona', 'chong', 'rama', 'kim', 'pmac', '690', 'ed', '71202', 'shen', 'ener', '507', 'chaton', '200512', 'bed', 'lite', 'mari', 'pmane', 'stat', 'rett', '416', '318', 'nikka', 'ttt', 'tick', 'slaw', 'bike', 'nita', 'marie', '9946', '94', 'tabe', '2200', '995', '187', 'das', '61040', '2274', '20333', '8169', 'red', '3080', 'cory', 'recon', 'sadd', '4844', 'dar1023', 'lor', 'bj', 'grey', 'rikon', '65', '512', 'rebel', '55', 'ses', '255', '33', 'fert', '868', 'vine', '1234', '3047', '30459', '1207', 'kine', 'ff', 'cond', '1120', 'adel', 'vaman', '1297', 'thor', 'dela', 'neddy', 'hide', 'shona', 'brar', 'nash', '58', '614', 'reba', '2286', '4545', 'cat', '1229', 'cynic', '6901', '99128', 'la', 'yale', '2229', 'sike', 'pine', '7000', '30436', '2020', '1209', '1123', '1569', 'jani', 'parola', 'max', '1101', 'lass', '100000', '560', '967', 'cvas', 'be', 'sin', '8193', '1989', 'bunt', '510', 'paddy', '5769', '24', 'praga', '4114', '3793', '466', '4230', 'bung', '1004', '2324', '65500', '1299', 'rsw', 'tigr', '2059', '1053', '834', 'alice', '9443', '7345', 'nany', '1005', '5420', 'mo', 'cook', 'noone', 'nana', '164', 'fudd', 'nancey', 'isha', '1231', 'alan', 'edd', '199', '406', 'kina', 'mace', 'pbones', 'mere', '6236', '140', '314', 'moss', 'come', 'colon', 'vendor', 'zx', 'rossss', 'ben', 'pa', '3000', 'tess', '5611', 'pond', 'core', 'ronan', '100', 'keb', 'ness', '52', 'cock', 'mel', '2003', 'coboy', 'kinane', 'stare', '4236', 'ramd', 'rose', 'babe', 'chand', '824', 'bob', '2959', 'nikon', 'vato', '775', 'pam', 'bink', '9116', 'rent', 'op', 'jano', 'barel', '12179', '80', 'pee', 'tita', '7959', 'dane', 'mereb', 'mate', '3312', 'mic', 'pero', 'man1', 'big', 'pin', 'wey', '1665', '543', '820', '623', '220', 'lala', '8319', 'sbur', 'deby', 'nara', 'hoa', '3040', 'nolee', 'ruby', '2399', '67', 'naner', 's1234', '801', '8006', '921', 'rrr', 'spaner', '347', '12000', '1269', '4', '2346', 'tmor', '31990', 'elk', 'new', 'mint', '0', '47', 'loner', '112201', '34', '1145', 'koni', 'naren', 'rat', 'rille', 'ronder', 'gore', '30123', '2005', '809', 'ksssss', 'ctan', 'ssssssss', '3459', 'namo', 'ann', '50', '612', '1991', '1149', 'cp', 'NON', 'manta', 'morey', 'pel', 'tina', '2127', 'dock', '5720', 'real1', 'rock', 'grid', '4469', '40', 'coon', '1000', 'sico', '1576', '3003', '9542', 'home', '6', 'sted', 'marina1', 'hore', 'rute', 'matss', 'po', '123235', '130', 'monman', 'pino', '717', 'matty', 'mec', 'tine', '235', '12534', 'passs', '1981', 'ride', '1165', 'dina', '209', 'parr', 'clove', '8833', '11243', '3991', '116', '8690', 'jr', '3234', '1001', 'x', 'fame', 'mande', '975', 't123', '433', 'sun', '30197', 'mariar', '1', '808', 'here', '1020', 'gus', '22073', 'poss', '430', 'bando', '5000', 'line', 'gen', 'bee', '873', '14', 'made', '1093', '124', 'bead', '15', '42300', '210', '404', '8808', '8170', 'mori', '20000', 'mike', '7111', 'penn', 'bama', 'v', 'nene', '804', 'rodeo', 'rockon', '143', '881', 'cane', 'cake', '957', '121914', '1952', '2304', 'dyla', 'landa', 'peen', 'mass', 'neel', '2379', 'mady', 'r1953', '61', 'glen', '31', '369', '5800', '7744', 'stl', 'ssi', 'mole', 'tyty', '3', '999', '31105', '521', 'sak', 'theage', '1223', '7110', '1122', '1444', '242', '11302', 'ross', 'fess', 'trane', 'dew', '8743', '62092', '1215', 'chak', 'nina', 'lorela', 'wanna', '756', '112', 'hiss', '16', 'chaz', '1959', '101', 'boo', 'rerer', '8112', '5233', 'conan', '909', 'cada', 'wang', 'roady', 'tg', '7205', '3490', '52190', 'tang', 'raine1', 'mila', 'Ar', '705', 'der', '303', '92364', 'kane', 'ssssssssss', 'beef', 'tad', 'chon', 'rob', '11167', '5329', '887', '726', '1790', '954', '3810', 'shonda', 'rony', '3523', '878', 'd', 's123', '12331', 'wedr', '82099', '205', 'teen', '20013', '244', '3200', 'name', '1170', 'fed', '23', 'b', 'monda', '2123', '212', '55555', 'don', 'code', '320000', 'jon', 'pia', 'mala', 'nick', '3107', 'corey', 'cole', '991', '657', '46', '2344', 'risk', '11420', '6623', 'naes', 'cassy', '5123', 'ravel', 'slll', 'moni', 'tack', '99', '50000', 'ron13', 'dell', '19544', 'mack1', 'flit', '399', 'adante', '3004', '847', '42057', '32000', '8312', '562', '1737', 'sonar', '148', 'nenene', 'nino', 'rtse', 'kick', '8829', 'sana', '9881', 'lova', '30987', 'art', '112481', '2930', 'sar', 'ming', '22300', 'morena', '4111', '2120', 'stone', 'kush', 'nona', 'ss123', '5054', 'joey', '9', '5417', '548', '420', 'crow', '91081', '1217', '9005', '1512', 'toni', 'cal', 'molin', 'piss', 'tous', '4501', 'rondee', '1923', 'chas', '122', '1277', 'mans', 'sssss', 'ch', 'cane1', '7220', 'hi', 'rip', 'anil', '540000', '60230', '3357', '1099', 'moma', 'cue', 'ser', '8011', 'rice', 'tan', 'mika', '200000', 'sade', 'mama', '201', 'lake', '890', 'merand', '6976', '8888', '5833', 'model', '330', 'fer', 'more', '850', '930', 'car', '5424', '70120', 'mash', 'vd', '195169', 'nada', 'no', 'ssc', '211', 'pick', '1192', '1951', 'sspare', '917', 'slags', 'bon25', '6339', '20', '1800', '4459', '1140', '5490', '1930', '1014', 'mara', '3297', 'bora', 'nissan', '1098', '152000', 'hanama', 'rewa', 'nish', 'newer', '869', 'f', 'p12345', '8130', 'madd', '828', '800', '3110', '1996', 'mada', '1301', 'sadam', '169', 'mani', 'boneca', 'rog', '745', '13120', 'n1414', 'hikky', 'boss', 'adam', '4003', '876', 'jars', 'dron', '1156', '12004', 'cass', '8891', '114', 'stc', '431', '2420', 'nig', 'jhan', '300', 'reer', '714', '12456', 'vena', '1296', 'cre', 'k', 'dones', 'slon', '2011', '1973', '8505', '2014', 'lone', '771', '694', '711', '100005', 'lites', 'sssssss', '72407', '23323', 'char', '505', 'nine', 'hoe', 'shon', 'codes', '5', 'ss1290', '2069', 'mona', 'manor', '1056', 'mom', 'ssss', 'nor', '1899', 'rere', 'carss', 'schor', '455', '13200', 'teal', 'grt', '90499', 'rs04', 'key', '9041', '1283', '735', 'nikn', 'hally', '6565', 'rain', 'andi', 'anom', 'maga', 'cc', '12109', '1438', 'reg', '1113', '8019', '12355', 'cona', '618', 'arty1', 'rona', 'nala', 'nora', '69', '843', 'pie', '1999', 'dadd', 'renee', 'tol', '102', '822', 'cba', 'madone', '11', '987', '12', '219', '30133', 'binder', '1241', '11112', 'snare', '20118', '569', '315', 'crew', '248', '307', 'none', 'bola', 'bess', '8149', '2140', 'ramer', 'we', '44', '30', '5092', 'macs', 'crss', 'dade', 'ada', 'r12000', 'dong', '35', '704', 'cachi', '184', 'drenda', '2325', 'madu', '48', '165', 'me', 'antec', 'joy', '8340', '9209', 'chili', '1162', 'g', 'donn', '20454', 'rk', '456', '888', 'man', 'dsss', 'coic', 'dona', '815', '18111', '12073', 'tela', 'kenda', 'dee', 'ma', '777', 'g123', 'swina', 'rew', '122375', 'mg', '2302', '1003', 'cheri', 'chin', '919', 'mini', '6992', 'anand', '317', '340', 'boy', 'free', 'crex', 'jay', 'amita', 'mac', 'flip', '1200', '1902', 'gonad', '421', 'shades', '8448', 'ho', 'neon', '54', '2470', 'rich', 'indy', 'dan', 'das11', 'cone', 'm221', '34006', 'mat', 'tana', 'max123', 'ty', '127', '11075', 'becky', 'niky14', '1006', '1054', '1371', '91222', '3119', 'miton', 'joni', 'shug', 'ssss40', 'renu', '969', 'mich', '1070', '749', '405', 'dora', 'ratedr', 'eshan', 'moon', '401', '699', 'mano', '74', '2355', 'moe', '6957', 'q', '1230', 'yaay', '1954', '830', 'shobe', '1205', 'chandan', '301', 'por', 'jh', 'dd', 'cove', 'licks', '319', 'dont', 'nali', '1007', 'ht', '109', '38', 'tssb', '3743', 'moli', '1116', 'rana', '21', 'lads', 'swag', '1243', '7', 'swak', 'spa', '8079', 'avag', 'wer', '8123', 'josse', '89', 'fuck', '112112', '123169', 'ej', '1251', '1550', 'gere', '1022', 'hey', 'r123', '2434', '547', '2320', 'mess', '580', '619', 'belad', 'net', 'rita', 'were', '4043', 'bode', 'russ', 'sone', 'adey', 'sis', 'deb', 'mir', 'day', '3443', '41699', '59509', 'flomo', '7290', 'smores', '755', 'pos1', '441', '819', 'rack', '13', '203', '410', 'ini', 'manda', 'rowe', '426', 'sss1', '56', 'bit', '81080', 'nono', 'tna', 'minger', '2300', '4773', '311', 'bond', 'ricki', '1188', '33004', 'yes', '81231', '4055', 'js', '2230', '1013', 'bree', 'cate', 'nikil', '103', '8082', 'catt', '7099', '8873', '412', 'dins', '1388', '1998', '12110', 'tac', 'red8', 'nordan', '337', 'mell', 'hedo', '516', 'blk', '403', '9743', '2009', '1847', 'tree', 'tele', 'cade', '923', 'ass', 'missa', '7699', '816', 'mesa', '119', 'fore', '1199', '243', '1104', '345', '720', 'monn', '54080', 'nacho', 'mt', '8399', '6040', 'felt', '1690', 'chad', '2099', 'nis', '8886', 'ggg', 'boro', 'ps', '2912', '254', '222', 'blonde', 'sls', '323', 'hyt', 'dias', 'cholo', '944', '17', 'danda', 'cro', 'ted', '805', 'jand', 'lik', 'veme', '982', '1204', 'pole', 'ande', 'canal', 'try', '113', '8823', '1124', '343', 'west', '8379', '126', 'rbll', '1225', '1119', 'done', '1519', '93', 'zene', '62', 'mont', '207', 'welme', '3123', '331', '2206', '1203', 'randy', 'a', '123', '252', 'pro', 'nessa', '350', 'mars', 'fun', 'rise', 'p', 'halo', '905', '1434', 'pal', 'milan', 'miko', 'moron', '5421', 'rty', '1698', 'd600', '32', 'gross', '357', 'grip', '117', '6914', '146', '810', '1051', '511', '502', '202', '344', 'ANDY', 'cray', '9944', 'mata', '1233', 'tete', 'gay', 'less', 'cani', 'teach', 'rand', '1110', '8003', '5210', '309', '13723', 'mode', '170', 'crip', '41', '1125', 'teri', 'dandd', '423', 'cave', '2217', '1338', '80199', 'asll', 'nader', '1100', '14499', 'anon3', '72000', '1901', 'rara', 'slow', '234', '904', '379', '6547', '8179', '354', '1002', '1105', '10903', 'boy1', 'ibe', '1219', 'nonon', '9107', 'date', 'wendel', 'meme', '1118', 'nero', 'nemo', '1940', 'clod', 'binty', 'mandd', 'bec', '5650', 'rex', 'realme', '9949', '214', 'this', 'rick', '101111', 'seer', '145', 'vel', 'pass1', 'Pp', 'jona', 'onee', 'dog', 'dang', 'nadia', '1208', '197', 'stag', 'aron', 'narena', 'pang', 'tera', '8122', 'dika', '12300', 'ASIA', '701', '85', '108', 'ss1234', '637', '2334', '5576', '4312', 'pass', '913', 'des1', 'bal', 'need', 'us', 'monis', '1010', 'sss', '715', 'nate', 'jade', 'poon', 'fena', 'dre', '900', 'yessss', 'co', '399999', '2445', 'patada', '2056', 'ssssss1', '91', '1232000', 'wind', 'hana', 'ricki1', '1127', 'cande', 'konig', 'war', 'berton', '333', 'rell', 'read', 'pelle', '1523', '2007', 'depo', 'love', '551400', 'fly', '1040', 'there', '5143', '39', '2000', 'teta', 'kandel', '5200', 'ken', '107', 'stine', 'chan', 'randa', 'redr', 'anbo', 'fudi', 'navy', 'rave', '4999', 'te', 'mach', '854', 'tish', '2233', '1520', '811', '160', 'mart', 'veto', '71', '2911', 'canda', '8880', '12771', '8200', '893', 'ten', 'sher', 'toy', 'con22', '3094', '500', '1779', '77', 'back', '6023', 'bren', 'mana', '8105', 'cocky', 'demo', 'nude', '129', 'sharon', 'dare', 'ronn', 'miss', '1928', '2054', 'nena', '524', 'riky', 'the', 'male', 'chess'}\n"
          ]
        }
      ]
    }
  ]
}